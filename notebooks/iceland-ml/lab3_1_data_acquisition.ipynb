{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc70a2b2",
   "metadata": {},
   "source": [
    "# Lab 3.1: Sentinel-2 Data Download from Copernicus Dataspace\n",
    "\n",
    "**Part of the Iceland ML Course: Sentinel-2 Classification Project**\n",
    "\n",
    "This notebook demonstrates how to acquire and download Sentinel-2 satellite imagery using the Copernicus Dataspace Ecosystem API for land classification tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "| Lab | Topic | Status |\n",
    "|-----|-----------|--------|\n",
    "| Lab 1 | HPC Access Setup | ‚úÖ Previous |\n",
    "| Lab 2 | Jupyter-JSC & Git | ‚úÖ Previous |\n",
    "| Lab 3.1 | **Data Download (Copernicus API)** | üîÑ **Current** |\n",
    "| Lab 3.2 | Data Preprocessing & Patch Extraction | ‚¨ú Next |\n",
    "| Lab 4 | Understanding Transformers | ‚¨ú Next |\n",
    "| Lab 4.1 | Training on Sentinel-2 Data | ‚¨ú Next |\n",
    "| Lab 5 | Distributed Training (Multi-GPU) | ‚¨ú Next |\n",
    "| Lab 6 | Validation & Performance Metrics | ‚¨ú Next |\n",
    "| Lab 7 | Foundation Models & TerraToRCH | ‚¨ú Final |\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this lab, you will:\n",
    "- Register for Copernicus Dataspace access\n",
    "- Authenticate with the Copernicus Dataspace API\n",
    "- Search for Sentinel-2 Level 2A imagery by date, location, and cloud cover\n",
    "- Download Sentinel-2 SAFE archives\n",
    "- Organize downloaded data for preprocessing\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "This lab focuses on the **Data Acquisition** phase of the project pipeline:\n",
    "\n",
    "```\n",
    "Data Download from Copernicus (Lab 3.1) ‚Üê You are here\n",
    "    ‚Üì\n",
    "Data Preprocessing & Patch Extraction (Lab 3.2)\n",
    "    ‚Üì\n",
    "Model Training (Lab 4+)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lab focuses on:\n",
    "1. **Copernicus Dataspace Registration**: Setting up your account and credentials\n",
    "2. **API Authentication**: Using OAuth2 to access the API\n",
    "3. **Searching Sentinel-2 Data**: Finding imagery by date, location, and quality\n",
    "4. **Downloading SAFE Archives**: Getting full Sentinel-2 products\n",
    "5. **Data Organization**: Structuring files for Lab 3.2 preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d801e6f",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Registration\n",
    "\n",
    "First, you need to register for Copernicus Dataspace access and set up authentication credentials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfa2f9c",
   "metadata": {},
   "source": [
    "### Step 1: Register and Create OAuth2 Client\n",
    "\n",
    "**Important**: The Copernicus Dataspace uses OAuth2 authentication. Follow these steps:\n",
    "\n",
    "1. Go to **Copernicus Browser Dashboard**: https://browser.dataspace.copernicus.eu/\n",
    "2. Login to your account (create one if needed)\n",
    "3. Click your profile (top right) ‚Üí **User Settings**\n",
    "4. Locate **\"OAuth clients\"** section\n",
    "5. Click **\"Create\"** to register a new OAuth client\n",
    "6. **Give it a name** (e.g., \"Iceland-ML-Lab\")\n",
    "7. Set expiration or select \"Never expire\" (recommended for HPC)\n",
    "8. Click **\"Create\"**\n",
    "9. Copy your **Client ID** and **Client Secret** and save them securely\n",
    "\n",
    "‚ö†Ô∏è **Security Note**: Your client secret won't be shown again! Save it immediately.\n",
    "\n",
    "**Your credentials:**\n",
    "- **Client ID**: `sh-....`\n",
    "- **Client Secret**: `<YOUR SECRET>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d55496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# For visualization later\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01529bd",
   "metadata": {},
   "source": [
    "### Step 2: Configure OAuth2 Client Credentials\n",
    "\n",
    "OAuth2 Client Credentials is the recommended authentication method for server-to-server communication and HPC jobs. Store credentials securely as environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your Copernicus Dataspace OAuth2 Client Credentials\n",
    "# Register OAuth client in Dashboard: https://browser.dataspace.copernicus.eu/\n",
    "\n",
    "# Option 1: Set as environment variables (recommended for HPC)\n",
    "# export COPERNICUS_CLIENT_ID=\"your_client_id\"\n",
    "# export COPERNICUS_CLIENT_SECRET=\"your_client_secret\"\n",
    "\n",
    "# Option 2: Direct assignment (for testing only - DO NOT COMMIT TO GIT!)\n",
    "COPERNICUS_CLIENT_ID = os.getenv('COPERNICUS_CLIENT_ID', 'sh-...')\n",
    "COPERNICUS_CLIENT_SECRET = os.getenv('COPERNICUS_CLIENT_SECRET', '<Your Secret>')\n",
    "\n",
    "# Copernicus Dataspace API endpoints\n",
    "AUTH_URL = \"https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token\"\n",
    "SEARCH_URL = \"https://catalogue.dataspace.copernicus.eu/odata/v1/Products\"\n",
    "DOWNLOAD_URL = \"https://zipper.dataspace.copernicus.eu/odata/v1/Products\"\n",
    "\n",
    "print(\"‚úì Credentials configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56ce125",
   "metadata": {},
   "source": [
    "### Step 3: Set Environment Variables (Optional)\n",
    "\n",
    "Store your credentials as environment variables instead of hardcoding them.\n",
    "\n",
    "**On your HPC system:**\n",
    "\n",
    "```bash\n",
    "# Add to ~/.bashrc or ~/.bash_profile\n",
    "export COPERNICUS_CLIENT_ID=\"<Your ID>\"\n",
    "export COPERNICUS_CLIENT_SECRET=\"<Your Secret>\"\n",
    "\n",
    "# Then reload\n",
    "source ~/.bashrc\n",
    "```\n",
    "\n",
    "**Verify setup:**\n",
    "\n",
    "```bash\n",
    "# Check variables are set\n",
    "echo $COPERNICUS_CLIENT_ID\n",
    "echo $COPERNICUS_CLIENT_SECRET\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4fb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_access_token(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Get OAuth2 access token from Copernicus Dataspace using Client Credentials flow.\n",
    "    \n",
    "    This is the recommended method for server-to-server authentication and HPC jobs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    client_id : str\n",
    "        OAuth2 Client ID (starts with 'sh-')\n",
    "    client_secret : str\n",
    "        OAuth2 Client Secret\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Access token if successful, None otherwise\n",
    "    \"\"\"\n",
    "    data = {\n",
    "        \"grant_type\": \"client_credentials\",\n",
    "        \"client_id\": client_id,\n",
    "        \"client_secret\": client_secret,\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(AUTH_URL, data=data, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        token_data = response.json()\n",
    "        \n",
    "        # Extract token and expiration\n",
    "        access_token = token_data[\"access_token\"]\n",
    "        expires_in = token_data.get(\"expires_in\", 3600)\n",
    "        \n",
    "        print(f\"‚úì Token obtained (valid for {expires_in//60} minutes)\")\n",
    "        return access_token\n",
    "        \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        if e.response.status_code == 401:\n",
    "            print(\"‚ùå Authentication failed: Invalid credentials\")\n",
    "            print(\"   ‚úó Check your CLIENT_ID and CLIENT_SECRET\")\n",
    "            print(\"   ‚úó CLIENT_ID should start with 'sh-'\")\n",
    "        else:\n",
    "            print(f\"‚ùå HTTP {e.response.status_code}: {e.response.text}\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Authentication failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Get access token\n",
    "print(\"Authenticating with Copernicus Dataspace...\")\n",
    "access_token = get_access_token(COPERNICUS_CLIENT_ID, COPERNICUS_CLIENT_SECRET)\n",
    "\n",
    "if access_token:\n",
    "    print(\"‚úì Successfully authenticated\")\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "else:\n",
    "    print(\"‚ùå Authentication failed.\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Check environment variables are set:\")\n",
    "    print(f\"   COPERNICUS_CLIENT_ID = {COPERNICUS_CLIENT_ID[:15]}...\")\n",
    "    print(f\"   COPERNICUS_CLIENT_SECRET = {COPERNICUS_CLIENT_SECRET[:15]}...\")\n",
    "    print(\"2. Verify credentials in Copernicus Dashboard\")\n",
    "    print(\"3. See COPERNICUS_SETUP.md for detailed instructions\")\n",
    "    headers = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd2879c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Define Search Parameters\n",
    "\n",
    "Specify your study area, date range, and quality criteria for Sentinel-2 imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3cd679",
   "metadata": {},
   "source": [
    "### Define Region of Interest and Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b30e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Region of Interest (ROI) as a bounding box\n",
    "# Format: POLYGON((lon lat, lon lat, ...))\n",
    "# Example: Bavarian region (Germany) - has CORINE coverage\n",
    "# Note: You will be selecting an MGRS tile within this region\n",
    "\n",
    "# Bounding box coordinates [min_lon, min_lat, max_lon, max_lat]\n",
    "# Bavarian region (Central Europe)\n",
    "min_lon, min_lat = 8.0, 47.0\n",
    "max_lon, max_lat = 14.0, 49.5\n",
    "\n",
    "# Create WKT POLYGON for API query\n",
    "roi_polygon = f\"POLYGON(({min_lon} {min_lat},{max_lon} {min_lat},{max_lon} {max_lat},{min_lon} {max_lat},{min_lon} {min_lat}))\"\n",
    "\n",
    "# Define date range\n",
    "start_date = '2018-03-01T00:00:00.000Z'\n",
    "end_date = '2018-10-31T23:59:59.999Z'\n",
    "\n",
    "# Maximum cloud cover percentage (30% to get good data availability)\n",
    "max_cloud_cover = 30\n",
    "\n",
    "print(f\"Search Parameters:\")\n",
    "print(f\"  Region: Bavarian region (Central Europe with CORINE coverage)\")\n",
    "print(f\"  Bounding Box: ({min_lon}, {min_lat}) to ({max_lon}, {max_lat})\")\n",
    "print(f\"  Date Range: {start_date[:10]} to {end_date[:10]}\")\n",
    "print(f\"  Max Cloud Cover: {max_cloud_cover}%\")\n",
    "print(f\"\\nNote: Sentinel-2 divides the globe into MGRS tiles (100√ó100 km each).\")\n",
    "print(f\"Your search will find all tiles intersecting this region.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b6def6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Search for Sentinel-2 Data\n",
    "\n",
    "Query the Copernicus Dataspace catalog for Sentinel-2 Level 2A imagery matching your criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526a852",
   "metadata": {},
   "source": [
    "### Search Sentinel-2 Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb6fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_sentinel2(start_date, end_date, roi_polygon, max_cloud_cover):\n",
    "    \"\"\"\n",
    "    Search for Sentinel-2 L2A products in Copernicus Dataspace\n",
    "    \"\"\"\n",
    "    # Build OData filter query\n",
    "    filters = [\n",
    "        f\"Collection/Name eq 'SENTINEL-2'\",\n",
    "        f\"Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'S2MSI2A')\",\n",
    "        f\"ContentDate/Start gt {start_date}\",\n",
    "        f\"ContentDate/Start lt {end_date}\",\n",
    "        f\"OData.CSC.Intersects(area=geography'SRID=4326;{roi_polygon}')\",\n",
    "        f\"Attributes/OData.CSC.DoubleAttribute/any(att:att/Name eq 'cloudCover' and att/OData.CSC.DoubleAttribute/Value lt {max_cloud_cover})\"\n",
    "    ]\n",
    "    \n",
    "    filter_query = \" and \".join(filters)\n",
    "    \n",
    "    params = {\n",
    "        \"$filter\": filter_query,\n",
    "        \"$orderby\": \"ContentDate/Start asc\",\n",
    "        \"$top\": 1000  # Increased to get full date range across all tiles\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(SEARCH_URL, params=params, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        results = response.json()\n",
    "        return results.get('value', [])\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "print(\"‚úì Search function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2de56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Searching for Sentinel-2 products...\")\n",
    "products = search_sentinel2(start_date, end_date, roi_polygon, max_cloud_cover)\n",
    "\n",
    "print(f\"\\n‚úì Found {len(products)} Sentinel-2 L2A products\")\n",
    "print(f\"‚úì All products have <{max_cloud_cover}% cloud cover (filtered server-side)\")\n",
    "print(f\"\\nThese products span multiple MGRS tiles over your region.\")\n",
    "print(f\"Select one MGRS tile and download ~4 acquisitions.\\n\")\n",
    "print(f\"First 5 products:\")\n",
    "for i, product in enumerate(products[:5]):\n",
    "    name = product.get('Name', 'Unknown')\n",
    "    date = product.get('ContentDate', {}).get('Start', 'N/A')[:10]\n",
    "    size = product.get('ContentLength', 0) / (1024**3)\n",
    "    \n",
    "    print(f\"  {i+1}. {name}\")\n",
    "    print(f\"     Date: {date}, Size: {size:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03f71b",
   "metadata": {},
   "source": [
    "### Group Products by MGRS Tile\n",
    "\n",
    "Before downloading, let's organize products by MGRS tile to ensure we download multiple acquisitions of the same tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e506eca-a069-4d05-a98c-836c81352a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group products by MGRS tile\n",
    "from collections import defaultdict\n",
    "\n",
    "tiles = defaultdict(list)\n",
    "for product in products:\n",
    "    product_name = product.get('Name', '')\n",
    "    # Extract MGRS tile from product name (e.g., T32UPD from S2A_MSIL2A_..._T32UPD_...)\n",
    "    tile_id = product_name.split('_')[5] if len(product_name.split('_')) > 5 else 'Unknown'\n",
    "    tiles[tile_id].append(product)\n",
    "\n",
    "# Display available tiles and their acquisition counts\n",
    "print(\"Available MGRS Tiles and Acquisition Counts:\")\n",
    "print(\"=\" * 50)\n",
    "for tile_id, tile_products in sorted(tiles.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "    print(f\"\\nTile {tile_id}: {len(tile_products)} acquisitions\")\n",
    "    for i, product in enumerate(tile_products[:5]):  # Show first 5\n",
    "        date = product.get('ContentDate', {}).get('Start', 'N/A')[:10]\n",
    "        size = product.get('ContentLength', 0) / (1024**3)\n",
    "        print(f\"  {i+1}. {date} - {size:.2f} GB\")\n",
    "    if len(tile_products) > 5:\n",
    "        print(f\"  ... and {len(tile_products) - 5} more\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"\\nRecommendation: Choose a tile with 4+ acquisitions for training data diversity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1583f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a tile to work with (choose the one with most acquisitions, or specify manually)\n",
    "# Option 1: Automatic - select tile with most acquisitions\n",
    "selected_tile = max(tiles.items(), key=lambda x: len(x[1]))[0] if tiles else None\n",
    "\n",
    "# Option 2: Manual selection - uncomment and specify tile ID\n",
    "# selected_tile = \"T32UPD\"  # Replace with your chosen tile\n",
    "\n",
    "if selected_tile:\n",
    "    tile_products = tiles[selected_tile]\n",
    "    num_acquisitions = len(tile_products)\n",
    "    \n",
    "    print(f\"Selected MGRS Tile: {selected_tile}\")\n",
    "    print(f\"Total acquisitions available: {num_acquisitions}\")\n",
    "    \n",
    "    # Select 4 evenly spaced acquisitions for temporal diversity\n",
    "    num_to_select = 4\n",
    "    if num_acquisitions >= num_to_select:\n",
    "        # Calculate indices for evenly spaced selection\n",
    "        indices = [int(i * (num_acquisitions - 1) / (num_to_select - 1)) for i in range(num_to_select)]\n",
    "        selected_products = [tile_products[i] for i in indices]\n",
    "    else:\n",
    "        # If fewer than 4 acquisitions, use all of them\n",
    "        selected_products = tile_products\n",
    "        indices = list(range(len(tile_products)))\n",
    "    \n",
    "    print(f\"\\nSelected {len(selected_products)} evenly-spaced acquisitions for temporal diversity:\")\n",
    "    print(\"=\" * 70)\n",
    "    for i, (idx, product) in enumerate(zip(indices, selected_products)):\n",
    "        name = product.get('Name', 'Unknown')\n",
    "        date = product.get('ContentDate', {}).get('Start', 'N/A')[:10]\n",
    "        size = product.get('ContentLength', 0) / (1024**3)\n",
    "        print(f\"  {i+1}. [{idx+1}/{num_acquisitions}] {date} - {size:.2f} GB\")\n",
    "        print(f\"      {name}\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nThese acquisitions span the full date range for better training data diversity.\")\n",
    "else:\n",
    "    print(\"‚ùå No tiles found. Adjust your search parameters.\")\n",
    "    selected_products = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bdb45a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Download Sentinel-2 Products\n",
    "\n",
    "Download selected Sentinel-2 SAFE archives to your local or HPC storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78468d42",
   "metadata": {},
   "source": [
    "### Download Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001d7d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_product(product, output_dir, access_token):\n",
    "    \"\"\"\n",
    "    Download a Sentinel-2 product from Copernicus Dataspace\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    product : dict\n",
    "        Product metadata from search results\n",
    "    output_dir : str\n",
    "        Directory to save downloaded file\n",
    "    access_token : str\n",
    "        OAuth2 access token\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Path to downloaded file, or None if failed\n",
    "    \"\"\"\n",
    "    product_id = product['Id']\n",
    "    product_name = product['Name']\n",
    "    \n",
    "    # Create download directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Output file path\n",
    "    output_file = os.path.join(output_dir, f\"{product_name}.zip\")\n",
    "    \n",
    "    # Check if already downloaded\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"‚ö† File already exists: {product_name}.zip\")\n",
    "        return output_file\n",
    "    \n",
    "    # Build download URL\n",
    "    download_url = f\"{DOWNLOAD_URL}({product_id})/$value\"\n",
    "    \n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading: {product_name}\")\n",
    "        print(f\"  Size: {product['ContentLength'] / (1024**3):.2f} GB\")\n",
    "        \n",
    "        # Stream download with progress\n",
    "        with requests.get(download_url, headers=headers, stream=True, timeout=300) as response:\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            total_size = int(response.headers.get('content-length', 0))\n",
    "            block_size = 8192\n",
    "            downloaded = 0\n",
    "            \n",
    "            with open(output_file, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=block_size):\n",
    "                    if chunk:\n",
    "                        f.write(chunk)\n",
    "                        downloaded += len(chunk)\n",
    "                        \n",
    "                        # Print progress every 100 MB\n",
    "                        if downloaded % (100 * 1024 * 1024) < block_size:\n",
    "                            progress = (downloaded / total_size) * 100 if total_size > 0 else 0\n",
    "                            print(f\"  Progress: {progress:.1f}% ({downloaded / (1024**3):.2f} GB)\")\n",
    "        \n",
    "        print(f\"‚úì Download complete: {output_file}\")\n",
    "        return output_file\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Download failed: {e}\")\n",
    "        # Clean up partial download\n",
    "        if os.path.exists(output_file):\n",
    "            os.remove(output_file)\n",
    "        return None\n",
    "\n",
    "print(\"‚úì Download function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb71d98",
   "metadata": {},
   "source": [
    "### Download A Selected Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define download directory (modify for your HPC storage)\n",
    "download_dir = \"/p/scratch/training2600/hashim1/data\"\n",
    "\n",
    "# Download the selected product\n",
    "if products and access_token:\n",
    "    downloaded_file = download_product(products[0], download_dir, access_token)\n",
    "    if downloaded_file:\n",
    "        print(f\"\\n‚úì Product saved to: {downloaded_file}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot download: No products found or authentication failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de446a4",
   "metadata": {},
   "source": [
    "### Download Multiple Acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823610a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the evenly-spaced acquisitions from the selected tile\n",
    "download_dir = \"/p/scratch/training2600/hashim1/data\"\n",
    "\n",
    "if selected_tile and access_token and selected_products:\n",
    "    print(f\"Downloading {len(selected_products)} evenly-spaced acquisitions from tile {selected_tile}...\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, product in enumerate(selected_products):\n",
    "        date = product.get('ContentDate', {}).get('Start', 'N/A')[:10]\n",
    "        print(f\"\\n--- Downloading {i+1}/{len(selected_products)} ({date}) ---\")\n",
    "        download_product(product, download_dir, access_token)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"‚úì Downloaded {len(selected_products)} acquisitions from tile {selected_tile}\")\n",
    "    print(f\"‚úì Acquisitions are evenly spaced across the time range\")\n",
    "    print(f\"‚úì All files saved to: {download_dir}\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot download: No tile/products selected or authentication failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77948f9-e8b8-4a85-8169-7116aabf3e34",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86172b3c-ae85-4284-9e7c-bc9103ded9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def extract_and_visualize_sentinel2(zip_path, output_dir=None):\n",
    "    \"\"\"\n",
    "    Extract a Sentinel-2 ZIP file and create an RGB visualization.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    zip_path : str\n",
    "        Path to the Sentinel-2 ZIP file\n",
    "    output_dir : str, optional\n",
    "        Directory to extract to. If None, extracts to same directory as ZIP.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Path to extracted SAFE directory\n",
    "    \"\"\"\n",
    "    import zipfile\n",
    "    import rasterio\n",
    "    from rasterio.plot import show\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = os.path.dirname(zip_path)\n",
    "    \n",
    "    # Extract ZIP file\n",
    "    print(f\"Extracting: {os.path.basename(zip_path)}\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        # Get the SAFE directory name (first item in the archive)\n",
    "        safe_dir = zip_ref.namelist()[0].split('/')[0]\n",
    "        safe_path = os.path.join(output_dir, safe_dir)\n",
    "        \n",
    "        if os.path.exists(safe_path):\n",
    "            print(f\"‚ö† Already extracted: {safe_dir}\")\n",
    "        else:\n",
    "            zip_ref.extractall(output_dir)\n",
    "            print(f\"‚úì Extracted to: {safe_path}\")\n",
    "    \n",
    "    return safe_path\n",
    "\n",
    "\n",
    "def visualize_sentinel2_rgb(safe_path, figsize=(12, 12)):\n",
    "    \"\"\"\n",
    "    Create an RGB visualization from Sentinel-2 SAFE directory.\n",
    "    \n",
    "    Uses bands B04 (Red), B03 (Green), B02 (Blue) at 10m resolution.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    safe_path : str\n",
    "        Path to the extracted .SAFE directory\n",
    "    figsize : tuple\n",
    "        Figure size for the plot\n",
    "    \"\"\"\n",
    "    import rasterio\n",
    "    from rasterio.enums import Resampling\n",
    "    \n",
    "    # Find the 10m resolution bands (B02, B03, B04)\n",
    "    # Path pattern: .SAFE/GRANULE/*/IMG_DATA/R10m/*_B0X_10m.jp2\n",
    "    granule_path = os.path.join(safe_path, 'GRANULE')\n",
    "    \n",
    "    if not os.path.exists(granule_path):\n",
    "        print(f\"‚ùå GRANULE directory not found in {safe_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get the tile subdirectory\n",
    "    tile_dirs = [d for d in os.listdir(granule_path) if os.path.isdir(os.path.join(granule_path, d))]\n",
    "    if not tile_dirs:\n",
    "        print(\"‚ùå No tile directories found\")\n",
    "        return\n",
    "    \n",
    "    tile_dir = os.path.join(granule_path, tile_dirs[0])\n",
    "    \n",
    "    # Try R10m directory first (newer format), then IMG_DATA (older format)\n",
    "    r10m_path = os.path.join(tile_dir, 'IMG_DATA', 'R10m')\n",
    "    img_data_path = os.path.join(tile_dir, 'IMG_DATA')\n",
    "    \n",
    "    if os.path.exists(r10m_path):\n",
    "        band_dir = r10m_path\n",
    "        band_pattern = '*_B0{}_10m.jp2'\n",
    "    else:\n",
    "        band_dir = img_data_path\n",
    "        band_pattern = '*_B0{}.jp2'\n",
    "    \n",
    "    # Find band files\n",
    "    bands = {}\n",
    "    for band_num in ['2', '3', '4']:\n",
    "        pattern = os.path.join(band_dir, band_pattern.format(band_num))\n",
    "        matches = glob.glob(pattern)\n",
    "        if matches:\n",
    "            bands[f'B0{band_num}'] = matches[0]\n",
    "        else:\n",
    "            # Try alternative pattern for older format\n",
    "            alt_pattern = os.path.join(band_dir, f'*B0{band_num}*.jp2')\n",
    "            alt_matches = glob.glob(alt_pattern)\n",
    "            if alt_matches:\n",
    "                bands[f'B0{band_num}'] = alt_matches[0]\n",
    "    \n",
    "    if len(bands) < 3:\n",
    "        print(f\"‚ùå Could not find all RGB bands. Found: {list(bands.keys())}\")\n",
    "        print(f\"   Searched in: {band_dir}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"‚úì Found bands: {list(bands.keys())}\")\n",
    "    \n",
    "    # Read bands with downsampling for visualization (full resolution can be huge)\n",
    "    downsample_factor = 10  # Read at 1/10 resolution for faster display\n",
    "    \n",
    "    rgb_bands = []\n",
    "    for band_name in ['B04', 'B03', 'B02']:  # RGB order\n",
    "        with rasterio.open(bands[band_name]) as src:\n",
    "            # Calculate new dimensions\n",
    "            new_height = src.height // downsample_factor\n",
    "            new_width = src.width // downsample_factor\n",
    "            \n",
    "            # Read with resampling\n",
    "            band_data = src.read(\n",
    "                1,\n",
    "                out_shape=(new_height, new_width),\n",
    "                resampling=Resampling.average\n",
    "            )\n",
    "            rgb_bands.append(band_data)\n",
    "    \n",
    "    # Stack into RGB array\n",
    "    rgb = np.stack(rgb_bands, axis=-1)\n",
    "    \n",
    "    # Normalize for visualization (typical Sentinel-2 values range 0-10000)\n",
    "    # Use percentile-based stretching for better visualization\n",
    "    p2, p98 = np.percentile(rgb[rgb > 0], (2, 98))\n",
    "    rgb_normalized = np.clip((rgb - p2) / (p98 - p2), 0, 1)\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # RGB composite\n",
    "    axes[0].imshow(rgb_normalized)\n",
    "    axes[0].set_title('Sentinel-2 RGB Composite (B4-B3-B2)', fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # False color (NIR-Red-Green) if available\n",
    "    # For now, show a histogram of the data\n",
    "    axes[1].hist(rgb[:,:,0].flatten()[::100], bins=50, alpha=0.7, label='Red (B04)', color='red')\n",
    "    axes[1].hist(rgb[:,:,1].flatten()[::100], bins=50, alpha=0.7, label='Green (B03)', color='green')\n",
    "    axes[1].hist(rgb[:,:,2].flatten()[::100], bins=50, alpha=0.7, label='Blue (B02)', color='blue')\n",
    "    axes[1].set_xlabel('Reflectance Value')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].set_title('Band Value Distribution', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].set_xlim(0, 5000)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"S2_vis.png\")\n",
    "    \n",
    "    # Print some metadata\n",
    "    with rasterio.open(bands['B04']) as src:\n",
    "        print(f\"\\nImage Metadata:\")\n",
    "        print(f\"  Original size: {src.width} x {src.height} pixels\")\n",
    "        print(f\"  Resolution: {src.res[0]}m x {src.res[1]}m\")\n",
    "        print(f\"  CRS: {src.crs}\")\n",
    "        print(f\"  Bounds: {src.bounds}\")\n",
    "    \n",
    "    return rgb_normalized\n",
    "\n",
    "print(\"‚úì Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33fd76d-17d6-46b2-b3a7-800dd032e6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the first downloaded acquisition\n",
    "# Adjust the path to match your download location\n",
    "\n",
    "def is_valid_zipfile(filepath):\n",
    "    \"\"\"Check if a file is a valid ZIP file.\"\"\"\n",
    "    try:\n",
    "        with zipfile.ZipFile(filepath, 'r') as zf:\n",
    "            return zf.testzip() is None\n",
    "    except (zipfile.BadZipFile, Exception):\n",
    "        return False\n",
    "\n",
    "if selected_products and access_token:\n",
    "    # Get the first downloaded product\n",
    "    first_product = selected_products[0]\n",
    "    product_name = first_product.get('Name', '')\n",
    "    \n",
    "    # Build possible paths - handle various naming conventions\n",
    "    # The product name might already end with .SAFE\n",
    "    base_name = product_name.rstrip('.SAFE') if product_name.endswith('.SAFE') else product_name\n",
    "    \n",
    "    possible_paths = [\n",
    "        os.path.join(download_dir, f\"{product_name}\"),           # Direct name (if it's a directory)\n",
    "        os.path.join(download_dir, f\"{product_name}.SAFE\"),      # With .SAFE suffix\n",
    "        os.path.join(download_dir, f\"{base_name}.SAFE\"),         # Base name with .SAFE\n",
    "        os.path.join(download_dir, f\"{product_name}.zip\"),       # With .zip suffix  \n",
    "        os.path.join(download_dir, f\"{base_name}.zip\"),          # Base name with .zip\n",
    "    ]\n",
    "    \n",
    "    safe_path = None\n",
    "    zip_path = None\n",
    "    \n",
    "    # Find the first existing path\n",
    "    for path in possible_paths:\n",
    "        if os.path.exists(path):\n",
    "            if os.path.isdir(path):\n",
    "                # It's a directory (SAFE format)\n",
    "                safe_path = path\n",
    "                print(f\"‚úì Found SAFE directory: {os.path.basename(path)}\")\n",
    "                break\n",
    "            elif path.endswith('.zip') and is_valid_zipfile(path):\n",
    "                # It's a valid ZIP file\n",
    "                zip_path = path\n",
    "                print(f\"‚úì Found valid ZIP file: {os.path.basename(path)}\")\n",
    "                break\n",
    "            elif path.endswith('.zip'):\n",
    "                # File exists but is not a valid ZIP - might be misnamed SAFE dir\n",
    "                print(f\"‚ö† Found {os.path.basename(path)} but it's not a valid ZIP file\")\n",
    "                print(\"  Checking if it might be a SAFE directory saved with wrong extension...\")\n",
    "                # Check if there's a SAFE directory with similar name\n",
    "                continue\n",
    "    \n",
    "    # If we found a ZIP file, extract it\n",
    "    if zip_path and not safe_path:\n",
    "        print(f\"\\nVisualizing: {os.path.basename(zip_path)}\")\n",
    "        print(\"=\" * 60)\n",
    "        safe_path = extract_and_visualize_sentinel2(zip_path)\n",
    "    \n",
    "    # Visualize if we have a SAFE path\n",
    "    if safe_path and os.path.isdir(safe_path):\n",
    "        print(f\"\\nVisualizing: {os.path.basename(safe_path)}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Create RGB visualization directly from SAFE directory\n",
    "        print(\"\\nCreating RGB visualization...\")\n",
    "        visualize_sentinel2_rgb(safe_path)\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"‚úì Visualization complete!\")\n",
    "        print(\"  - RGB composite shows the natural color view\")\n",
    "        print(\"  - Histogram shows the distribution of reflectance values\")\n",
    "        print(\"  - Data is ready for preprocessing in Lab 3.2\")\n",
    "    else:\n",
    "        # Last resort: try to find any .SAFE directory in download_dir\n",
    "        safe_dirs = glob.glob(os.path.join(download_dir, \"*.SAFE\"))\n",
    "        if safe_dirs:\n",
    "            safe_path = safe_dirs[0]\n",
    "            print(f\"\\nFound SAFE directory: {os.path.basename(safe_path)}\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            print(\"\\nCreating RGB visualization...\")\n",
    "            visualize_sentinel2_rgb(safe_path)\n",
    "            \n",
    "            print(\"\\n\" + \"=\" * 60)\n",
    "            print(\"‚úì Visualization complete!\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå No valid Sentinel-2 data found in: {download_dir}\")\n",
    "            print(f\"\\nSearched for:\")\n",
    "            for p in possible_paths[:3]:\n",
    "                print(f\"  - {p}\")\n",
    "            print(\"\\nTip: Check what files exist in your download directory:\")\n",
    "            print(f\"  ls -la {download_dir}\")\n",
    "else:\n",
    "    print(\"‚ùå No products selected or authentication failed\")\n",
    "    print(\"   Run the search and download cells first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9912b0fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: (Optional) Visualize with GEE\n",
    "\n",
    "If you want to quickly visualize search results before downloading, you can optionally use Google Earth Engine. This is optional and only for reconnaissance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47032383",
   "metadata": {},
   "source": [
    "### Optional: Visualize ROI with GEE\n",
    "\n",
    "If you want to preview your ROI using Google Earth Engine (optional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd15fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "\n",
    "ee.Authenticate()\n",
    "ee.Initialize()\n",
    "\n",
    "# Bounding box coordinates [min_lon, min_lat, max_lon, max_lat]\n",
    "# Bavarian region (Central Europe)\n",
    "min_lon, min_lat = 8.0, 47.0\n",
    "max_lon, max_lat = 14.0, 49.5\n",
    "\n",
    "# Create ee.Geometry.Rectangle (simpler approach)\n",
    "roi = ee.Geometry.Rectangle([min_lon, min_lat, max_lon, max_lat])\n",
    "\n",
    "# OR create from WKT string:\n",
    "# roi_polygon = f\"POLYGON(({min_lon} {min_lat},{max_lon} {min_lat},{max_lon} {max_lat},{min_lon} {max_lat},{min_lon} {min_lat}))\"\n",
    "# roi = ee.Geometry(roi_polygon, proj='EPSG:4326', geodesic=False)\n",
    "\n",
    "Map = geemap.Map(center=[48.0, 11.0], zoom=6)\n",
    "Map.addLayer(roi, {'color': 'FF0000'}, 'ROI')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254f8b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Data Organization\n",
    "\n",
    "Organize your downloaded data for efficient preprocessing in Lab 3.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b6c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended directory structure for the project\n",
    "import os\n",
    "\n",
    "base_dir = \"/p/scratch/training2600/YOUR_USERNAME/data\"\n",
    "\n",
    "directory_structure = {\n",
    "    \"sentinel2_data\": \"Downloaded Sentinel-2 ZIP files\",\n",
    "    \"sentinel2_extracted\": \"Extracted SAFE directories\",\n",
    "    \"sentinel2_geotiff\": \"Converted GeoTIFF files\",\n",
    "    \"corine_data\": \"CORINE land cover maps\",\n",
    "    \"training_data\": \"Preprocessed training patches\"\n",
    "}\n",
    "\n",
    "print(\"Recommended Directory Structure:\")\n",
    "print(f\"\\n{base_dir}/\")\n",
    "for dir_name, description in directory_structure.items():\n",
    "    dir_path = os.path.join(base_dir, dir_name)\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ {dir_name}/  # {description}\")\n",
    "    # Uncomment to create directories:\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "\n",
    "print(\"\\nTip: Create these directories before starting Lab 3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e509ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "\n",
    "1. **Register for Copernicus Dataspace**: Set up access via the Dataspace Browser\n",
    "2. **Authenticate via API**: Use OAuth2 to obtain access tokens\n",
    "3. **Search for Sentinel-2 Data**: Query the catalog by date, location, and cloud cover\n",
    "4. **Download SAFE Archives**: Retrieve full Sentinel-2 products as ZIP files\n",
    "5. **Organize Data**: Structure files for efficient preprocessing\n",
    "\n",
    "The downloaded Sentinel-2 ZIP files are ready for preprocessing in **Lab 3.2**.\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "### Before Moving to Lab 3.2\n",
    "\n",
    "**1. Verify Downloads**\n",
    "   - Check that Sentinel-2 ZIP files are complete (5-10 GB each)\n",
    "   - Note file paths for Lab 3.2\n",
    "\n",
    "**2. Extract ZIP Files** (Optional)\n",
    "   - Extract `.SAFE` directories from ZIP files\n",
    "   - Or let Lab 3.2 handle extraction automatically\n",
    "\n",
    "**3. Prepare Storage**\n",
    "   - Ensure sufficient disk space (~50 GB per tile including extracted data)\n",
    "   - Create directory structure as shown above\n",
    "\n",
    "### Next Lab: Lab 3.2 - Data Preprocessing & Patch Extraction\n",
    "\n",
    "In **Lab 3.2**, you'll:\n",
    "- Extract Sentinel-2 bands from SAFE format\n",
    "- Convert data to GeoTIFF for analysis\n",
    "- Extract 3x3 patches around LUCAS ground truth points\n",
    "- Create training data for model development\n",
    "\n",
    "### Data Pipeline Recap\n",
    "\n",
    "```python\n",
    "# Lab 3.1 produces:\n",
    "Sentinel-2 ZIP files (SAFE format)\n",
    "    ‚Üì\n",
    "# Lab 3.2 processes:\n",
    "Extract bands from SAFE archives\n",
    "Convert to GeoTIFF\n",
    "Extract patches around ground truth points\n",
    "    ‚Üì\n",
    "# Lab 4 trains:\n",
    "Transformer model on patches\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Resources & References\n",
    "\n",
    "- **Copernicus Dataspace Browser**: https://browser.dataspace.copernicus.eu/\n",
    "- **Copernicus Dataspace API Docs**: https://documentation.dataspace.copernicus.eu/APIs.html\n",
    "- **Sentinel-2 Product Specification**: https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2\n",
    "- **OData Protocol**: https://www.odata.org/\n",
    "\n",
    "---\n",
    "\n",
    "## Troubleshooting & FAQ\n",
    "\n",
    "**Q: I can't find the old Copernicus Hub (scihub.copernicus.eu) - where is it?**\n",
    "- The old SciHub was decommissioned. Use the new **Copernicus Dataspace Ecosystem** at https://dataspace.copernicus.eu/\n",
    "\n",
    "**Q: How do I get API credentials?**\n",
    "- Register at https://identity.dataspace.copernicus.eu/\n",
    "- Use the same credentials for both the browser and API access\n",
    "- No separate API key needed - OAuth2 tokens are generated on-the-fly\n",
    "\n",
    "**Q: Download is very slow - what can I do?**\n",
    "- Use HPC systems with high-bandwidth connections\n",
    "- Download during off-peak hours\n",
    "- Consider downloading multiple tiles in parallel with separate jobs\n",
    "\n",
    "**Q: What if I hit data limits?**\n",
    "- Copernicus Dataspace has generous free-tier limits\n",
    "- For large-scale downloads, request increased quotas\n",
    "\n",
    "**Q: Can I use the browser to download instead of the API?**\n",
    "- Yes! Use https://browser.dataspace.copernicus.eu/\n",
    "- Search for products visually\n",
    "- Download via the web interface\n",
    "- Better for small numbers of tiles\n",
    "\n",
    "**Q: How do I know which tile covers my area?**\n",
    "- Search by coordinates in the Dataspace Browser\n",
    "- The search results will show the MGRS tile ID\n",
    "\n",
    "---\n",
    "\n",
    "**Course Contact**: Refer to course materials for instructor email and office hours  \n",
    "**Last Updated**: February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a431126-f33a-428e-b7c9-9ea2a8b4c44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ML-EO Course)",
   "language": "python",
   "name": "ml_eo_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
